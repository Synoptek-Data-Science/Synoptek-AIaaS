{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cd31cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\anaconda\\lib\\site-packages (2.9.5)\n"
     ]
    }
   ],
   "source": [
    "# !pip install psycopg2-binary \n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1c5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noting starting time\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cfe0464-5337-48f0-940a-f1dc09aa8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import types\n",
    "import psycopg2 \n",
    "import io\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "# Create and configure logger\n",
    "logging.basicConfig(filename=\"Upload_autotaskdata_to_postgreSQL.log\", level=logging.INFO, format='%(asctime)s:%(name)s: %(message)s', filemode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4ddb712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12555, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dishita Neve\\AppData\\Local\\Temp\\ipykernel_13276\\2925796357.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df1.append(df2)\n",
      "C:\\Users\\Dishita Neve\\AppData\\Local\\Temp\\ipykernel_13276\\2925796357.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  userdata= df.append(df3)\n"
     ]
    }
   ],
   "source": [
    "# Reading ticket data from april to june\n",
    "df1 = pd.read_csv('iBAS-Apr-June-2022-Ticket Search Results.csv')\n",
    "# Reading ticket data from jan to march\n",
    "df2 = pd.read_csv('iBAS-Jan-Mar-2022-Ticket Search Results.csv')\n",
    "# Reading ticket data from july to august\n",
    "df3 = pd.read_csv('iBAS-July-Aug-2022-Ticket Search Results.csv')\n",
    "\n",
    "# Appending all data into single dataframe\n",
    "df = df1.append(df2)\n",
    "userdata= df.append(df3)\n",
    "# Droping duplicate ticket number with description\n",
    "userdata.drop_duplicates(subset=['Ticket Number','Description'],inplace=True)\n",
    "print(userdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26c3b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column names\n",
    "userdata.rename(columns = {'Title':'Ticket_Title'}, inplace = True)\n",
    "userdata.rename(columns = {'Ticket Number':'Ticket_Number'}, inplace = True)\n",
    "userdata.rename(columns = {'Issue Type':'Issue_Type'}, inplace = True)\n",
    "userdata.rename(columns = {'Sub-Issue Type':'Sub_Issue_Type'}, inplace = True)\n",
    "userdata.rename(columns = {'Create Date/Time':'Create_Date/Time'}, inplace = True)\n",
    "userdata.rename(columns = {'Complete Date/Time':'Complete_Date/Time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddddb8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Classification', 'Ticket_Number', 'Ticket_Title', 'Description',\n",
       "       'Account', 'Queue', 'Resources', 'Status', 'Priority', 'Created', 'Due',\n",
       "       'Impact', 'Issue_Type', 'Sub_Issue_Type', 'Resolution'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "226f8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "userdata.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aaa4148-4e23-44c7-b81d-94f666efa9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12555, 16)\n",
      "Index(['ID', 'Classification', 'Ticket_Number', 'Ticket_Title', 'Description',\n",
      "       'Account', 'Queue', 'Resources', 'Status', 'Priority', 'Created', 'Due',\n",
      "       'Impact', 'Issue_Type', 'Sub_Issue_Type', 'Resolution'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "userdata.columns = ['ID','Classification', 'Ticket_Number', 'Ticket_Title', 'Description',\n",
    "       'Account', 'Queue', 'Resources', 'Status', 'Priority', 'Created', 'Due',\n",
    "       'Impact', 'Issue_Type', 'Sub_Issue_Type', 'Resolution']\n",
    "print(userdata.shape)\n",
    "print(userdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bb0b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "userdata['Created'] = pd.to_datetime(userdata['Created'])\n",
    "userdata['Due'] = pd.to_datetime(userdata['Due'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b007187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the credentials here\n",
    "def load_envFile():\n",
    "    load_envFile.logger = logging.getLogger()\n",
    "    # Setting the threshold of logger to INFO \n",
    "    load_envFile.logger.setLevel(logging.INFO)\n",
    "    try:\n",
    "        ## load the dotenv\n",
    "        load_dotenv()\n",
    "\n",
    "        ## fetch the credentials\n",
    "        host = os.environ[\"host\"] \n",
    "        user = os.environ[\"user\"]\n",
    "        passwd = os.environ[\"passwd\"]\n",
    "        db_name = os.environ[\"db_name\"]\n",
    "        port = os.environ[\"port\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        load_envFile.logger.error(\"Error while establishing connection.\",e)\n",
    "        print(f'{e}')\n",
    "\n",
    "    else:\n",
    "        load_envFile.logger.info('Connection with data base established')\n",
    "        print('Connection with data base established')\n",
    "        return (host, user, passwd, db_name, port)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a80d7e3f-1961-4e38-a9a7-271ce394c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection with data base established\n",
      "Engine(postgresql://postgres:***@localhost:5432/Autotask)\n"
     ]
    }
   ],
   "source": [
    "# Loading .env file\n",
    "host, user, passwd, db_name, port = load_envFile()\n",
    "# Creating an engine of postgresql\n",
    "engine = create_engine('postgresql://'+user+':'+passwd+'@'+host+':'+str(port)+'/'+db_name, echo=False)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07a131a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successully uploaded data to database\n"
     ]
    }
   ],
   "source": [
    "def data_to_sql() :\n",
    "    data_to_sql.logger = logging.getLogger()\n",
    "    # Setting the threshold of logger to INFO \n",
    "    data_to_sql.logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Creating a dictionary of diff column names and data types\n",
    "    table_dtype = {\n",
    "                       'Id': types.INT(),\n",
    "                         'Classifications': types.VARCHAR(20),\n",
    "                          'Ticket_Number' : types.VARCHAR(20),\n",
    "                            'Ticket_Title' : types.VARCHAR(256),\n",
    "                            'Description' : types.VARCHAR(8000),\n",
    "                            'Account' : types.VARCHAR(20), \n",
    "                            'Queue' : types.VARCHAR(100), \n",
    "                            'Resources' : types.VARCHAR(200), \n",
    "                            'Status': types.VARCHAR(50), \n",
    "                            'Priority' : types.VARCHAR(100)  , \n",
    "                            'Created' : types.DATE(), \n",
    "                            'Due' :  types.DATE(),\n",
    "                               'Impact': types.VARCHAR(30),\n",
    "                            'Issue_Type' : types.VARCHAR(50), \n",
    "                            'Sub_Issue_Type':types.VARCHAR(100), \n",
    "                            'Resolution' :types.VARCHAR(8000)                }\n",
    "    try :\n",
    "        # Uploading dataframe to postgresql\n",
    "        userdata.to_sql(name='AutotaskTicketData', con=engine, if_exists='replace',\n",
    "                                 index=False, dtype = table_dtype)\n",
    "        data_to_sql.logger.info(\"Successully uploaded data to database\")\n",
    "        print('Successully uploaded data to database')\n",
    "    except Exception as e:\n",
    "        data_to_sql.logger.error(\"Error while loading data to postgreSQL.\",e)\n",
    "        print('Error while loading data to postgreSQL.')\n",
    "        \n",
    "data_to_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61108866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.525397062301636 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da1eae72-8a00-4084-b141-e7e43e525309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
